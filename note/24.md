# 24、阅读代码（2018-03-18，1.5h）



###课程目标：

* 阅读真实项目代码，并试着读懂和理解代码；



###课程作业：

在 github 上搜索“python”，选了一个排名靠前的项目，选择了其中一个“Google_News.py”的 python 文件。

Source: [My Python Examples - Github](https://github.com/geekcomputers/Python/blob/master/Google_News.py)


代码如下：

```
import bs4
from bs4 import BeautifulSoup as soup
from urllib.request import urlopen

def news():
	#my_url="https://news.google.com/news/rss"
	my_url="https://news.google.com/news/rss?ned=in&hl=en-IN"
	#To open the Given URL
	Client=urlopen(my_url) 
        s_url ="https://news.google.com/news/headlines/section/topic/SPORTS.en_in/Sports?ned=in&hl=en-IN&gl=IN"
        Client=urlopen(s_url)


	xml_page=Client.read()
	Client.close()

	soup_page=soup(xml_page,"xml")
	news_list=soup_page.findAll("item")
	
	for news in news_list:
			print(news.title.text)
			print(news.link.text)
			print(news.pubDate.text)
			print("-"*150)
	n=input()


news()
```



这是一个抓取Google_News RSS 源数据并筛选相关信息的 python文件，调用了3个库“bs4”、“BeautifulSoup”和“urlopen”，使用了两个语法，“urlopen()” 和“soup()”，输出 xml 文件内的 title、link、pubDate内容。



urlopen()

```
from urllib import urlopen
my_url = "https://www.douban.com/"
urldoc = urlopen(my_url)
print urldoc.read()

from urllib import urlopen
urldoc = urlopen("https://www.douban.com/").read()
print urldoc 
```



soup()

```
soup(xml_page,"xml")   #解析 xml 文件
```

`print soup.title`即读取 title 标签下的内容。


[python爬虫入门--Beautiful Soup库介绍及实例](http://blog.csdn.net/i_chaoren/article/details/63282877)



findAll()

查找所有匹配的组

```
news_list=soup_page.findAll("item")   
```



 循环语句  for a in b:    

```
for news in news_list:
			print(news.title.text)
			print(news.link.text)
			print(news.pubDate.text)
			print("-"*150)
	n=input()
```

